{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/XUgJiRmPnSaCcRRiCimx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polt3r/PLN/blob/main/Aula_06_Interpreta%C3%A7%C3%A3o_Sem%C3%A2ntica_e_Gram%C3%A1ticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo da Aula 06 - Análise Semântica e Relações Lexicais\n",
        "\n",
        ">- Introdução à análise semântica com foco no significado das palavras e suas relações.\n",
        "- Utilização de WordNet (NLTK) e funcionalidades do SpaCy (português) para:\n",
        "  - **Consulta de significados (synsets)** e exemplos de uso.\n",
        "  - **Identificação de relações semânticas** (sinonímia, antonímia, hiperonímia, hiponímia).\n",
        "  - **Extração de definições** e informações lexicais.\n",
        "- Organização e visualização de dados semânticos com `pandas` em DataFrames.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "22VgBm0fLLJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 01 - Representação do significado das palavras e frases com redes Semânticas."
      ],
      "metadata": {
        "id": "E7EkpqcaIo6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdIzfMtHIiJy",
        "outputId": "3d0a2ce1-a94d-4262-8b57-daa06c5be897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('beach_wagon.n.01'), Synset('car.n.01'), Synset('car.n.02'), Synset('cart.n.01')]\n",
            "beach_wagon\n",
            "car\n",
            "car\n",
            "cart\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "# banco de dados para utilização do sinônimos\n",
        "nltk.download('omw-1.4')\n",
        "# Corpus que relaciona as palavras em diversos idiomas - tradução automática\n",
        "\n",
        "# Método para encontrar os sinônimos da palavras indicada e o idioma\n",
        "sinonimos = wordnet.synsets(\"carro\", lang=\"por\")\n",
        "\n",
        "print(sinonimos) # imprime a lista gerada\n",
        "\n",
        "for s in sinonimos:\n",
        "    print(s.lemmas()[0].name())  # Mostra sinônimos da palavra\n",
        "    # s.lemmas(): Obtém a lista de lemmas (formas básicas das palavras) no synset atual.\n",
        "    # [0]: Pega o primeiro lemma da lista.\n",
        "    # .name(): Obtém o nome do lemma (o sinônimo em si).\n",
        "    # print(): Imprime o sinônimo na tela.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 02 - Representação do significado das palavras e frases por Vetores (embeddings)."
      ],
      "metadata": {
        "id": "OyKa0LNQI-II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_md\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Carregando o modelo pre treinado - modelo com relações entre palavras\n",
        "nlp = spacy.load('pt_core_news_md')\n",
        "\n",
        "# criação de objetos, com suas informações e vetores\n",
        "palavra1 = nlp('rei')\n",
        "palavra2 = nlp('rainha')\n",
        "\n",
        "# Calculo de similaridade dos objetos vetorizadas\n",
        "print(palavra1.similarity(palavra2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlAoaHyzI82W",
        "outputId": "dc8a0c1c-35c7-4ef4-e4d1-42abd6016471"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_md-3.8.0/pt_core_news_md-3.8.0-py3-none-any.whl (42.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-md\n",
            "Successfully installed pt-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "0.6001228094100952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo 03 - Árvore Sintática"
      ],
      "metadata": {
        "id": "MDy2fmFTJEho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy  # módulo para visualização de dependências\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "frase = \"O cachorro correu no parque.\"\n",
        "doc = nlp(frase)\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "CKqUJTUnJDKo",
        "outputId": "b21ccb53-6805-4865-c996-ee2d110a698b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"8a5092931389427496e7ffc31fbaf05d-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cachorro</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">correu</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">parque.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8a5092931389427496e7ffc31fbaf05d-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8a5092931389427496e7ffc31fbaf05d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8a5092931389427496e7ffc31fbaf05d-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8a5092931389427496e7ffc31fbaf05d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8a5092931389427496e7ffc31fbaf05d-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8a5092931389427496e7ffc31fbaf05d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8a5092931389427496e7ffc31fbaf05d-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8a5092931389427496e7ffc31fbaf05d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exemplo 04 - Ontologia"
      ],
      "metadata": {
        "id": "-kd-usJAJnQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2\n",
        "\n",
        "from owlready2 import *\n",
        "\n",
        "# Criando uma nova ontologia\n",
        "onto = get_ontology(\"http://exemplo.com/minha_ontologia.owl\")\n",
        "\n",
        "with onto:\n",
        "  class Animal(Thing): pass\n",
        "  class Mamifero(Animal): pass\n",
        "  class Cachorro(Mamifero): pass\n",
        "  class Gato(Mamifero): pass\n",
        "\n",
        "onto.save(\"minha_ontologia.owl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXiIiDsXJmO2",
        "outputId": "f56965a7-2d24-47dc-a525-14a73309f155"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting owlready2\n",
            "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=owlready2-0.47-cp311-cp311-linux_x86_64.whl size=24577497 sha256=dbe5dc2092f12a8c355e66e4a450473aaff6abfc0e61242106227fded2091afa\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/9a/a3/fb1ac6339caa859c8bb18d685736168b0b51d851af13d81d52\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Estudo de Caso 01 - Aplicação de Análise Semântica em um corpus"
      ],
      "metadata": {
        "id": "ZzZLwkQWJ2ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "# banco de dados léxico - agrupa palavras em conjuntos de sinônimos\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Acessar as funcionalidades como tokenização, análise sintática e vetores de pala"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7SCHGv4KVKq",
        "outputId": "6ad81ec4-661c-405d-f971-3961bed22ad8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 # 2. Reconhecimento de Entidades Nomeadas (NER)\n",
        "entities_data = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  entities_data.append({\n",
        "      \"Entidade\": ent.text,\n",
        "      \"Tipo\": ent.label_\n",
        "  })\n",
        "\n",
        "# 10 # Convertendo para DataFrame\n",
        "df_entities = pd.DataFrame(entities_data)\n",
        "print(\"\\nReconhecimento de Entidades:\")\n",
        "print(df_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhF6P5A9KmC_",
        "outputId": "e33872d0-0559-4b7c-fd0e-9e404373683a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reconhecimento de Entidades:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 # 3. Análise Semântica com WordNet\n",
        "semantic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  synsets = wn.synsets(token.text)\n",
        "  if synsets:\n",
        "    semantic_data.append({\n",
        "        \"Palavra\": token.text,\n",
        "        \"Significado\": synsets[0].definition(),\n",
        "        \"Exemplo\": synsets[0].examples()\n",
        "    })\n",
        "\n",
        "# 13 # Convertendo para DataFrame\n",
        "df_semantic = pd.DataFrame(semantic_data)\n",
        "print(\"\\nAnálise Semântica:\")\n",
        "print(df_semantic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHUjFdgoK5q7",
        "outputId": "58be3d36-32e3-473f-bbbd-f91ec717908d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Análise Semântica:\n",
            "  Palavra                                        Significado  \\\n",
            "0       O  a nonmetallic bivalent element that is normall...   \n",
            "1      no                                         a negative   \n",
            "\n",
            "                       Exemplo  \n",
            "0                           []  \n",
            "1  [his no was loud and clear]  \n"
          ]
        }
      ]
    }
  ]
}